import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory
import os
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime
import pytz

# å…³é—­ huggingface çš„ åŠ é€Ÿtokenizersç¼–ç 
os.environ["TOKENIZERS_PARALLELISM"] = "false"


@st.cache_resource
def load_vectorstore():
    embedding_model = HuggingFaceEmbeddings(model_name="moka-ai/m3e-base")
    return FAISS.load_local(
        "data/faiss_index", embedding_model, allow_dangerous_deserialization=True
    )


def get_beijing_time():
    """
    è¿”å›å½“å‰åŒ—äº¬æ—¶é—´ï¼šæ—¥æœŸ + æ—¶é—´ï¼›æ—¥æœŸï¼›è¿”å› AM æˆ– PM
    """
    tz = pytz.timezone("Asia/Shanghai")
    now = datetime.now(tz)
    return now.strftime("%Y-%m-%d %H:%M"), now.strftime("%p")


def main():
    # åˆå§‹åŒ–å‰ç«¯ç¯å¢ƒ
    st.set_page_config(page_title="åŒ»ç–—åŠ©æ‰‹RAG", layout="wide")
    st.title("åŒ»ç–—ç³»ç»Ÿé—®ç­”åŠ©æ‰‹ ")
    st.write("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼Œæ”¯æŒå¤šè½®è¿½é—®ã€‚")

    # åŠ è½½ FAISS
    vectorstore = load_vectorstore()
    load_dotenv()

    # åˆå§‹åŒ– LLM å’Œ prompt
    llm = ChatOpenAI(
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1",
        model="deepseek-chat",
    )

    output_parser = StrOutputParser()  # æŠŠç”Ÿæˆç»“æœè§£æä¸ºçº¯æ–‡æœ¬å­—ç¬¦ä¸²

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ä½ æ˜¯æœåŠ¡äºç—…æ‚£çš„åŒ»ç–—åŠ©æ‰‹ï¼Œè¯·æ¸©æŸ”è€å¿ƒã€ä¾æ®äº‹å®ä»¥åŠå†å²å¯¹è¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœç”¨æˆ·æç¤ºä¸æ¸…æ™°ï¼Œè¯·çŒœæµ‹ç”¨æˆ·æ¥ä¸‹æ¥æƒ³è¯´çš„å†…å®¹å¹¶ç»™åˆ°ç”¨æˆ·å¼•å¯¼ã€‚",
            ),
            MessagesPlaceholder(variable_name="history"),
            (
                "user",
                "{input}\nè¯·è¯¦ç»†è¯´æ˜ä½ æ˜¯å¦‚ä½•å¾—å‡ºç­”æ¡ˆçš„ï¼Œå±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚å¦‚æœæ£€ç´¢å†…å®¹æ— å…³ï¼Œè¯·è¯´æ˜ç†ç”±ã€‚",
            ),
        ]
    )

    # æ„é€  Streamlit èŠå¤© ä»¥åŠ å¯¹è¯å†å²
    if "history" not in st.session_state:
        st.session_state["history"] = []

    # è¾“å…¥æ¡†äº¤äº’
    user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")

    if user_input:

        # å±•ç¤ºç”¨æˆ·æé—®
        st.chat_message("user").write(user_input)

        # è·å–å½“å‰æ—¶é—´ä¿¡æ¯
        beijing_full_time, time_period = get_beijing_time()

        # è¿›è¡Œç¨ å¯†æ£€ç´¢ chunk
        dense_results = vectorstore.similarity_search(user_input, k=8)
        context = "\n\n".join([doc.page_content for doc in dense_results])

        # æ‹¼æ¥ prompt è¾“å…¥
        full_input = f"å½“å‰åŒ—äº¬æ—¶é—´ï¼š{beijing_full_time, time_period}\n\né—®é¢˜ï¼š{user_input}\n\nä»¥ä¸‹æ˜¯å¯èƒ½ç›¸å…³çš„åŒ»ç”Ÿæ’ç­ä¿¡æ¯ï¼š\n{context}"

        # æ˜¾ç¤ºæ£€ç´¢ç‰‡æ®µ
        with st.chat_message("assistant"):
            st.markdown("ğŸ“š **æ£€ç´¢åˆ°çš„å†…å®¹ç‰‡æ®µï¼š**")
            for i, doc in enumerate(dense_results):
                st.markdown(f"**ç‰‡æ®µ {i+1}:**")
                st.code(doc.page_content, language="markdown")

            st.markdown("**æ­£åœ¨æ¥å…¥å¤§æ¨¡å‹è¯­è¨€æ¨ç†ä¸­ï¼Œè¯·ç¨å€™...**")

        # æ„é€  LLM è¾“å…¥ï¼ˆå†å²è®°å½•+ç”¨æˆ·è¾“å…¥ï¼‰ï¼Œå¹¶è¿›è¡Œæ¨ç†
        inputs = {"history": st.session_state["history"], "input": full_input}
        answer = (prompt | llm | output_parser).invoke(inputs)

        # ä¿å­˜å¯¹è¯å†å²ï¼Œå¹¶åœ¨ä¸‹ä¸€æ¬¡èŠå¤©ä¸­å¹¶å…¥ prompt
        st.session_state["history"].append({"role": "user", "content": user_input})
        st.session_state["history"].append({"role": "assistant", "content": answer})

        # å±•ç¤ºå¯¹è¯å†å²ï¼ˆå€’åºæ¸²æŸ“ï¼‰
        for msg in st.session_state["history"]:
            if msg["role"] == "user":
                st.chat_message("user").write(msg["content"])
            else:
                st.chat_message("assistant").write(msg["content"])

        # æ¨ç†è¿‡ç¨‹å±•ç¤º
        if user_input:
            with st.expander("æ¨¡å‹æ¨ç†è¿‡ç¨‹ï¼ˆç‚¹å‡»å±•å¼€ï¼‰"):
                st.markdown("**åŸå§‹ç”¨æˆ·é—®é¢˜ï¼š**")
                st.code(user_input, language="markdown")

                st.markdown("**æ£€ç´¢åˆ°çš„å†…å®¹ç‰‡æ®µï¼š**")
                for i, doc in enumerate(dense_results):
                    st.markdown(f"**ç‰‡æ®µ {i+1}:**")
                    st.code(doc.page_content, language="markdown")

                st.markdown("**ä¼ ç»™æ¨¡å‹çš„å®Œæ•´ Prompt è¾“å…¥ï¼š**")
                st.code(full_input, language="markdown")

                st.markdown("**æœ€ç»ˆå›ç­”ï¼š**")
                st.code(answer, language="markdown")


# TODO: æ°¸ä¹…å‚¨å­˜å†å²ä¼šè¯ï¼›
if __name__ == "__main__":
    main()
